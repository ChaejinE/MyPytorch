{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "o_Modules",
      "provenance": [],
      "authorship_tag": "ABX9TyNwkLQXHtewTJB60AulFDC5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChaejinE/MyPytorch/blob/main/PyTorch_Tips_Details/o_Modules.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsrVIFJEXlGs"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPTv220PX1TX"
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQtNL_HYYBId"
      },
      "source": [
        "# Overview\n",
        "- Module : 여러 개의 작은 블록으로 구성된 큰 블록이 있을 때\n",
        "- Sequential : 레이어에서 작은 블록을 만들고 싶을 때\n",
        "- ModuleList : 일부 레이어 또는 빌딩 블록을 반복하면서 어떤 작업을 해야할 때\n",
        "- ModuleDict : 모델의 일부 블록을 매개 변수화 해야하는 경우 (?? activation의 기능이 예시랜다.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QUuPU_zYWAk"
      },
      "source": [
        "# Module\n",
        "- 가장 기본이 되는 block 단위\n",
        "- Conv -> BatchNorm -> ReLU 가 이어져서 사용되지만, 함수처럼 사용하지 못하는 것은 다소 비효율적인 것으로 보인다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCQg_gOWYgeT"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class CNNClassifier(nn.Module):\n",
        "  def __init__(self, in_c, n_classes):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_c, 32, kernel_size=3, stride=1, padding=1)\n",
        "    self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
        "    self.bn2 = nn.BatchNorm2d(32)\n",
        "\n",
        "    self.fc1 = nn.Linear(32 * 28 * 28, 1024)\n",
        "    self.fc2 = nn.Linear(1024, n_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = F.relu(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x)\n",
        "    x = F.relu(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1) # batch별로 flatten\n",
        "\n",
        "    x = self.fc1(x)\n",
        "    x = F.sigmoid(x)\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHOL-bW4Z2qK"
      },
      "source": [
        "# Sequential\n",
        "- 마치 컨테이너 처럼 Module을 담는 역할을 한다.\n",
        "- Sequential에 쌓은 순서대로 Module은 실행되고, 같은 Sequential에 쌓은 모듈은 한 단위처럼 실행된다.\n",
        "- 코드가 간결해진다.\n",
        "- 하지만 conv_block1, conv_block2 로 코드가 중복된다. 중복되는 코드를 함수로 빼면 더 간결하게 쓸 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSQvkNKfZhfu"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class CNNClassifier(nn.Module):\n",
        "  def __init__(self, in_c, n_classes):\n",
        "    super().__init__()\n",
        "    self.conv_block1 = nn.Sequential(\n",
        "        nn.Conv2d(in_c, 32, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.conv_block2 = nn.Sequential(\n",
        "        nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.decoder = nn.Sequential(\n",
        "        nn.Linear(32 * 28 * 28, 1024),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Linear(1024, n_classes)\n",
        "    )\n",
        "\n",
        "    self.fc1 = nn.Linear(32 * 28 * 28, 1024)\n",
        "    self.fc2 = nn.Linear(1024, n_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv_block1(x)\n",
        "    x = self.conv_bolck2(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.decoder(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bXfyP3rauth"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def conv_block(in_f, out_f, *args, **kwargs):\n",
        "  return nn.Sequential(\n",
        "        nn.Conv2d(in_f, out_f, *arg, **kwargs),\n",
        "        nn.BatchNorm2d(out_f),\n",
        "        nn.ReLU()\n",
        "  )\n",
        "\n",
        "class CNNClassifier(nn.Module):\n",
        "  def __init__(self, in_c, n_classes):\n",
        "    super().__init__()\n",
        "    self.conv_block1 = conv_block(in_c, 32, kernel_size=3, padding=1)\n",
        "    self.conv_block2 = conv_block(32, 64, kernel_size=3, padding=1)\n",
        "\n",
        "    self.decoder = nn.Sequential(\n",
        "        nn.Linear(32 * 28 * 28, 1024),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Linear(1024, n_classes)\n",
        "    )\n",
        "\n",
        "    self.fc1 = nn.Linear(32 * 28 * 28, 1024)\n",
        "    self.fc2 = nn.Linear(1024, n_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv_block1(x)\n",
        "    x = self.conv_bolck2(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.decoder(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcdbIRATcMvc"
      },
      "source": [
        "- 더 간결하게 만든 것이지만 encoder 부분이 계속 늘어난다면 좋은 방법은 아니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Acxu5vZjbg2B"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def conv_block(in_f, out_f, *args, **kwargs):\n",
        "  return nn.Sequential(\n",
        "        nn.Conv2d(in_f, out_f, *arg, **kwargs),\n",
        "        nn.BatchNorm2d(out_f),\n",
        "        nn.ReLU()\n",
        "  )\n",
        "\n",
        "class CNNClassifier(nn.Module):\n",
        "  def __init__(self, in_c, n_classes):\n",
        "    super().__init__()\n",
        "    self.encoder = nn.Sequential(\n",
        "        conv_block(in_c, 32, kernel_size=3, padding=1),\n",
        "        conv_block(32, 64, kernel_size=3, padding=1)\n",
        "    )\n",
        "\n",
        "    self.decoder = nn.Sequential(\n",
        "        nn.Linear(32 * 28 * 28, 1024),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Linear(1024, n_classes)\n",
        "    )\n",
        "\n",
        "    self.fc1 = nn.Linear(32 * 28 * 28, 1024)\n",
        "    self.fc2 = nn.Linear(1024, n_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.encoder(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.decoder(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGoZH4TpcSCy"
      },
      "source": [
        "- 예를들어\n",
        "```python\n",
        "self.encoder = nn.Sequential(\n",
        "            conv_block(in_c, 32, kernel_size=3, padding=1),\n",
        "            conv_block(32, 64, kernel_size=3, padding=1),\n",
        "            conv_block(64, 128, kernel_size=3, padding=1),\n",
        "            conv_block(128, 256, kernel_size=3, padding=1),\n",
        "\n",
        "        )\n",
        "```\n",
        "- 이런 경우 반복문을 이용해 코드를 간결하게 작성할 수 있다. (input, output의 Channel 수)\n",
        "- Input과 output의 channel 수는 list를 이용해 정의해 두는 방법을 많이 사용한다.\n",
        "  - 핵심은 **반복문을 사용하되 channel의 크기를 미리 저장해 두고 사용하면 된다는 것이다.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pbn8VlEgb4-c"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def conv_block(in_f, out_f, *args, **kwargs):\n",
        "  return nn.Sequential(\n",
        "        nn.Conv2d(in_f, out_f, *arg, **kwargs),\n",
        "        nn.BatchNorm2d(out_f),\n",
        "        nn.ReLU()\n",
        "  )\n",
        "\n",
        "class CNNClassifier(nn.Module):\n",
        "  def __init__(self, in_c, n_classes):\n",
        "    super().__init__()\n",
        "    self.enc_sizes = [in_c, 32, 64]\n",
        "    # N 번째 블럭의 output channel의 수가 N+1 번째 block의 input channel 수가 된다\n",
        "    # 이를 이용해 리스트를 교차로 접근한다.\n",
        "    self.conv_blocks = [conv_block(in_f, out_f, kernel_size=3, padding=1)\n",
        "                        for in_f, out_f in zip(self.enc_sizes, self.enc_sizes[1:])]\n",
        "\n",
        "    # *연산자를 리스트와 같이 사용하면 편하게 사용할 수 있다.\n",
        "    # container unpacking method\n",
        "    self.encoder = nn.Sequential(*conv_blocks)\n",
        "\n",
        "    self.decoder = nn.Sequential(\n",
        "        nn.Linear(32 * 28 * 28, 1024),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Linear(1024, n_classes)\n",
        "    )\n",
        "\n",
        "    self.fc1 = nn.Linear(32 * 28 * 28, 1024)\n",
        "    self.fc2 = nn.Linear(1024, n_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.encoder(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.decoder(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYz_EmY3dvnJ"
      },
      "source": [
        "a = [1, 2, 3]\n",
        "b = a[1:]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqfDc4qxdzSc",
        "outputId": "eb0760d6-4e80-4068-f9e1-5eaf1ec67ba8"
      },
      "source": [
        "list(zip(a, b))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 2), (2, 3)]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUTU_pP1d19V",
        "outputId": "947bdff8-4161-4d5e-88e5-b7a7e7e05e0e"
      },
      "source": [
        "a = [1,2,3,4,5]\n",
        "b = [10, *a]\n",
        "b"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10, 1, 2, 3, 4, 5]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhloCNEofLhz",
        "outputId": "fc1a4dc9-63cb-4a59-8695-03d7de5c3e06"
      },
      "source": [
        "c = [10, a]\n",
        "c"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10, [1, 2, 3, 4, 5]]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHiQ66kwfbUp"
      },
      "source": [
        "- 더 간결하게 정리해본 코드다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zlkl1vlLfMuK"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def conv_block(in_f, out_f, *args, **kwargs):\n",
        "  return nn.Sequential(\n",
        "        nn.Conv2d(in_f, out_f, *arg, **kwargs),\n",
        "        nn.BatchNorm2d(out_f),\n",
        "        nn.ReLU()\n",
        "  )\n",
        "\n",
        "def dec_block(in_f, out_f):\n",
        "  return nn.Sequential(\n",
        "      nn.Linear(in_f, out_f),\n",
        "      nn.Sigmoid()\n",
        "  )\n",
        "\n",
        "class CNNClassifier(nn.Module):\n",
        "  def __init__(self, in_c, enc_sizes, dec_size, n_classes):\n",
        "    super().__init__()\n",
        "    self.enc_sizes = [in_c, *enc_sizes]\n",
        "    self.dec_sizes = [32 * 28 * 28, *dec_sizes]\n",
        "\n",
        "    self.conv_blocks = [conv_block(in_f, out_f, kernel_size=3, padding=1)\n",
        "                        for in_f, out_f in zip(self.enc_sizes, self.enc_sizes[1:])]\n",
        "    self.encoder = nn.Sequential(*conv_blocks)\n",
        "\n",
        "    self.dec_blocks = [dec_block(in_f, out_f)\n",
        "                        for in_f, out_f in zip(self.dec_sizes, self.dec_sizes[1:])]\n",
        "    self.decoder = nn.Sequential(*dec_blocks)\n",
        "    \n",
        "    self.last = nn.Linear(self.dec_sizes[-1], n_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.encoder(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.decoder(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ol60ip5ggge"
      },
      "source": [
        "# ModuleList\n",
        "- Module 리스트 형태로 담을 때 사용한다.\n",
        "  - Sequential과 동일하게 저장한 모듈을 차례대로 접근하며 실행\n",
        "  - 차이는 내부적으로 forward를 사용하냐 안하냐이다.\n",
        "- Sequential은 내부 레이어에 접근하여 어떤 작업을 하는데에 어려움이 있다.\n",
        "- 반면, ModuleList는 리스트 형태로 각 Module에 접근해서 사용할 수 있다.\n",
        "  - forward 함수에서 for문을 통해 iterate 하며 Module들을 실행한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed8YLywIgOEO",
        "outputId": "7731f2a6-9757-496b-e033-a6f68a09a0bb"
      },
      "source": [
        "class MyModule(nn.Module):\n",
        "  def __init__(self, sizes):\n",
        "    super().__init__()\n",
        "    self.layers = nn.ModuleList([nn.Linear(in_f, out_f) for in_f, out_f in zip(sizes, sizes[1:])])\n",
        "    self.trace = []\n",
        "\n",
        "  def forward(self, x):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "      self.trace.append(x)\n",
        "    return x\n",
        "\n",
        "model = MyModule([1, 16, 32])\n",
        "model(torch.rand((4, 1)))\n",
        "[print(trace.shape) for trace in model.trace]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 16])\n",
            "torch.Size([4, 32])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKP8ppS-h6-J"
      },
      "source": [
        "# ModuleDict\n",
        "- 모듈을 딕셔너리 형태로 사용할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yrs3JXRNhil8",
        "outputId": "0ae78167-6fc5-4c9c-92b8-193d949767b9"
      },
      "source": [
        "def conv_block(in_f, out_f, activation=\"relu\", *args, **kwargs):\n",
        "  activations = nn.ModuleDict([\n",
        "                               [\"lrelu\", nn.LeakyReLU()],\n",
        "                               ['relu', nn.ReLU()]\n",
        "  ])\n",
        "\n",
        "  return nn.Sequential(\n",
        "      nn.Conv2d(in_f, out_f, *args, **kwargs),\n",
        "      nn.BatchNorm2d(out_f),\n",
        "      activations[activation]\n",
        "  )\n",
        "\n",
        "print(conv_block(1, 32, 'lrelu', kernel_size=3, padding=1))\n",
        "print(conv_block(1, 32, 'relu', kernel_size=3, padding=1))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): LeakyReLU(negative_slope=0.01)\n",
            ")\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GkLRvozigim"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}